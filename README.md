# XFloats.jl

Some numerically intensive computations are performed. Some deeply enfolded learning strategems
are applied. Some pharmaceutical designs are to be simulated.  Each domain is approached twice.
The first time computation proceeds with `Float32s` or `Float16s`, as appropriaate to their respective
problem domains and algorithmic design.  The second time computation proceeds with `XFloat32s` or
`XFloat64s`, in correspondance with the floating point types used initially.  The processing times
are similar, one takes eight hours, the other 7.5 hours.

hours and at most 6 hours to complete.


dayindistinguishable to a swing of 10% separated by within a few percent of one another .

The second results are more accurate than the first results.


The first time Float32s are used.  The second time XFloat32s are used.
64is completed in similar time with augmented accuracy.

and provides 
The , augmented accuracy, rationals with unreal performance <sup>[ùì™](#source)</sup>

##### Copyright ¬© 2017-2019 by Jeffrey Sarnoff. This work is released under The MIT License.

- there are two XFloat types, (precisely two and intentionally not three) 
- XFloat16
- XFloat32

##### _ XFloat are floating point values o_e___X__traccurate

(a) an `XFloat` is a specialized type for precision enhanced floating point values
    These `eXraaccurateFloat`
    - `XFloat16` stores, carries, applies, recieves and retrieves 16 bit floating point values
    - `XFloat32` stores, carries, applies, recieves and retrieves 32 bit floating point values
    
(b) an `XFloat` travels when stored in an xkit

is stored for travel in an xkit) kind of floating point there are two
-- values of type `XFloat16` or of type `XFloat32`
- `XFloats` perform arithemtic just as fast as do the corresponding system floating point types.
the systare just as fast the system floats 
`XFloats` come in two sizes: 16-bit and 32-bit.  There is no 64-bit XFloat type.There are two XFloat Types: `XFloat16` and `XFloat32`
XFloats compute at greater precision than Floats (more significant bits) more accurate, very fast 
Precision-doubled floating point types almost as fast as the system floats Float32, Float64,.
for high-performance with 99% of the performace of hardware floats.





### benchmarks

```
        relative speeds
          (32)   (64)    (mixed)

add:     1.0     1.08    1.07
mul:     1.08    1.08    1.07
arith:   0.87    1.07    1.07
fma:     0.93    1.08    1.42
muladd:  1.29    0.94    1.07

```
